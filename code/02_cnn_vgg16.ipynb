{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GaDhBDayduI",
    "outputId": "59b0a93f-d1dd-4831-8c55-99f548492458"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# For my first CNN model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# For the CNN model using VGG16\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Performancer Metric Analysis\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpnjJVvYM7fF"
   },
   "source": [
    "# Importing and Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1x-RZK51fmJ4",
    "outputId": "6bb76cb6-faaa-4d9b-9c4a-bb30fa34350e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37175 files belonging to 6 classes.\n",
      "Using 29740 files for training.\n",
      "Found 37175 files belonging to 6 classes.\n",
      "Using 7435 files for validation.\n"
     ]
    }
   ],
   "source": [
    "directory = \"../plots/spectograms\"\n",
    "\n",
    "# Create a generator for my training set\n",
    "train = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),  # I might want this as 256, 256 if my results are bad. # Dont need to rescale bc all images are the same size\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")\n",
    "\n",
    "# Creating a generator for my validaton (=testing) set\n",
    "test = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7B9Qip6uiNq",
    "outputId": "dd6092f7-7057-4d50-dea8-4d62ce5e14c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolder 'ANG': 6345 images\n",
      "Subfolder 'NEU': 5435 images\n",
      "Subfolder 'SAD': 6355 images\n",
      "Subfolder 'HAP': 6355 images\n",
      "Subfolder 'FEA': 6340 images\n",
      "Subfolder 'DIS': 6345 images\n"
     ]
    }
   ],
   "source": [
    "# Confirming no class imbalance for my 6 target outputs\n",
    "# If data is imbalanced, use class weights.\n",
    "\n",
    "base_directory = \"../plots/spectograms\"\n",
    "\n",
    "image_counts = {}\n",
    "\n",
    "# Iterate over subdirectories\n",
    "for subfolder in os.listdir(base_directory):\n",
    "    subfolder_path = os.path.join(base_directory, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Count the number of files with .png extension in the subfolder\n",
    "        num_images = len([filename for filename in os.listdir(subfolder_path) if filename.endswith('.png')])\n",
    "        image_counts[subfolder] = num_images\n",
    "\n",
    "# Print counts for each subfolder\n",
    "for subfolder, count in image_counts.items():\n",
    "    print(f\"Subfolder '{subfolder}': {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the first CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxiaXnOqfmMq"
   },
   "outputs": [],
   "source": [
    "# Instantiate the CNN model\n",
    "cnn = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "cnn.add(Conv2D(filters=32,\n",
    "               kernel_size=(3,3),\n",
    "               strides = (1,1), # to conform with padding\n",
    "               padding = 'same',\n",
    "               activation='relu',\n",
    "               input_shape=(128, 128, 3),\n",
    "               kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Add a MaxPooling2D layer to downsample\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a second convolutional layer\n",
    "cnn.add(Conv2D(filters=64,  # Increase the number of filters, base 2\n",
    "               kernel_size=(3, 3),\n",
    "               strides=(1, 1),\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Add a second MaxPooling2D layer to downsample\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output from the convolutional layer\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Add a dense layer: softmax activation for multi-class classification\n",
    "cnn.add(Dense(units=6,\n",
    "              activation='softmax',\n",
    "              kernel_regularizer=l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XH7aLaROa0K0",
    "outputId": "0cf45751-03d8-49d5-b26b-a7c35c1a7b77"
   },
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sn4RVyZJa0Ps"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "cnn.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "  optimizer = 'adam',\n",
    "    metrics = ['accuracy'] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5F72nqioAUub"
   },
   "outputs": [],
   "source": [
    "# Add option for Early Stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    patience=5,           # Number of epochs with no improvement after which training will stop\n",
    "    restore_best_weights=True  # Restore the model weights from the epoch with the best validation loss\n",
    ")\n",
    "\n",
    "# Add option for ModelCheckpoint callback (to save the best model)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_cnn.h5',  # Filepath to save the best model\n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True,  # Save only the best model\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4fZvwEZa0YZ",
    "outputId": "9f5f2d15-8c2d-4aed-efb5-8d1b83188002"
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = cnn.fit(train,\n",
    "        validation_data = test,\n",
    "        epochs = 25,\n",
    "        batch_size = 64,\n",
    "        callbacks = [early_stopping, model_checkpoint],\n",
    "        verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "o0-qYa7Ga0cn",
    "outputId": "590baa43-479d-4dcc-822c-e1a67a4c66d2"
   },
   "outputs": [],
   "source": [
    "# Evaluate model history\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xticks(range(0,25), range(1,26))\n",
    "plt.legend()\n",
    "plt.title('CNN Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0rMjDjWZX0G",
    "outputId": "9724f790-87f8-4efe-a2bd-a9042c8badec"
   },
   "outputs": [],
   "source": [
    "# Call preds\n",
    "predictions = cnn.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMoezy_dCkS9"
   },
   "source": [
    "# Now using a VGG16 model with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIg5pMtV5N9v",
    "outputId": "66dd7bad-8f0c-4ec7-d758-1f80f124a4ff"
   },
   "outputs": [],
   "source": [
    "# Loading the pre-trained VGG16 model without the top classification layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oI4IVIVCNNDw"
   },
   "outputs": [],
   "source": [
    "# Adding custom classification layers on top of VGG16 base:\n",
    "# Because I need to format for my problem of multi-class with 6 target outputs\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(6, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SlPIK5q5NNGJ"
   },
   "outputs": [],
   "source": [
    "# Creating the VGG-16 base model\n",
    "vgg16_model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dZqo69htDfNS"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# Unfreeze some layers\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "# I decided to make only the last 4 layers trainable for optimization\n",
    "\n",
    "# Compile the model\n",
    "vgg16_model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    # Default learning rate is 0.001. Larger learning rate = model will converge faster = takes less time to learn, so better for optimization\n",
    "    # I used tf.keras.optimizers.legacy.Adam over tf.keras.optimizers.Adam because the former runs slowly on M1/M2 macs.\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eO5NMwJhR_u",
    "outputId": "a1e73cf3-27b2-4d54-9855-e7ad08c047c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,764,166\n",
      "Trainable params: 15,764,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NM8XA9agEfUJ",
    "outputId": "2fb51cc8-debb-45af-b720-0ea5b572b9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 12:00:50.197029: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732/930 [======================>.......] - ETA: 9:54 - loss: 2.4325 - accuracy: 0.1711"
     ]
    }
   ],
   "source": [
    "# Add option for Early Stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Add option for ModelCheckpoint callback (to save the best model)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_vgg16.h5',  # Filepath to save the best model\n",
    "    monitor='val_accuracy',  # Metric to monitor\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = vgg16_model.fit(\n",
    "    train,\n",
    "    validation_data=test,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Baseline Accuracy # is acc / # of classes so acc / 6 --> 100/6 = ~17%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOcjvoXJEll8",
    "outputId": "32f6b889-1910-4498-ddf9-5e74e40ecf38"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = vgg16_model.evaluate(test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4ll90IIYLzO",
    "outputId": "7ac17a5a-fab4-43a3-b7ab-e45e2c3894ee"
   },
   "outputs": [],
   "source": [
    "# Display the number of epochs used in the best model\n",
    "best_model_epochs = len(history.history['val_accuracy'])\n",
    "print(\"Number of epochs in the best model:\", best_model_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "JFjxZuieks2J",
    "outputId": "2762f6db-3842-4dbc-c1c4-31f8a2738a42"
   },
   "outputs": [],
   "source": [
    "# Evaluate model history\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xticks(range(0,25), range(1,26))\n",
    "plt.legend()\n",
    "plt.title('VGG16 Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2Hj11Dtks4r"
   },
   "outputs": [],
   "source": [
    "# Call preds\n",
    "predictions = vgg16_model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a multi-class confusion matrix for the VGG16 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Matrix\n",
    "\n",
    "target_names = ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']\n",
    "print(classification_report(test, predictions, target_names=target_names))\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
